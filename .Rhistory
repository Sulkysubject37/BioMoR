method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
sampling = "smote"   # or "up", "down"
)
fit <- train(Label ~ .,
data = df_emb,
method = "rf",
metric = "ROC",     # use ROC as optimization metric
trControl = ctrl)
print(fit)
library(caret)
library(recipes)
library(themis)     # for step_smote
library(pROC)
library(dplyr)
set.seed(123)
data$Label   <- factor(ifelse(data$Label == 1, "Active", "Inactive"),
levels = c("Inactive", "Active"))
df_emb$Label <- factor(ifelse(df_emb$Label == 1, "Active", "Inactive"),
levels = c("Inactive", "Active"))
data <- data %>%
mutate(across(where(is.integer), as.numeric))
ctrl <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
)
rec_raw <- recipe(Label ~ ., data = data %>% select(-SMILES)) %>%
step_smote(Label)
fit_raw <- train(
rec_raw,
data = data %>% select(-SMILES),   # remove SMILES
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
rec_emb <- recipe(Label ~ ., data = df_emb) %>%
step_smote(Label)
fit_emb <- train(
rec_emb,
data = df_emb,
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
rec_emb <- recipe(Label ~ ., data = df_emb) %>%
step_upsample(Label)
fit_emb <- train(
rec_emb,
data = df_emb,
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
ctrl <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final",
sampling = "up"   # caretâ€™s built-in upsampling
)
rec_raw <- recipe(Label ~ ., data = data %>% select(-SMILES)) %>%
step_smote(Label)
fit_raw <- train(
rec_raw,
data = data %>% select(-SMILES),   # remove SMILES
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
rec_emb <- recipe(Label ~ ., data = df_emb) %>%
step_upsample(Label)
fit_emb <- train(
rec_emb,
data = df_emb,
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
rec_emb <- recipe(Label ~ ., data = df_emb)
fit_emb <- train(
rec_emb,
data = df_emb,
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
table(df_emb$Label)
df_emb$Label <- droplevels(df_emb$Label)
table(df_emb$Label)
data$Label <- factor(ifelse(data$Label == 1, "Active", "Inactive"),
levels = c("Inactive", "Active"))
# Rebuild embeddings dataframe
df_emb <- data.frame(Label = data$Label, emb)
table(df_emb$Label)
data <- read.csv("~/Desktop/drug_induced_ml/drug_induced_autoimmunity_prediction/DIA_trainingset_RDKit_descriptors.csv")
unique(data$Label)
data$Label <- factor(data$Label, levels = c(0,1), labels = c("Inactive", "Active"))
table(data$Label)
set.seed(123)
data$Label   <- factor(data$Label, levels = c(0,1),
labels = c("Inactive", "Active"))
df_emb <- data.frame(Label = data$Label, emb)
ctrl <- trainControl(
method = "cv",
number = 5,
sampling = "smote",         # balance within each fold
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
)
# --- (1) RF on raw descriptors ---
rec_raw <- recipe(Label ~ ., data = data %>% select(-SMILES)) %>%
step_smote(Label)
fit_raw <- train(
rec_raw,
data = data %>% select(-SMILES),
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
data <- data %>% filter(!is.na(Label))
# 2. Convert Label to factor (Active/Inactive)
data$Label <- factor(data$Label, levels = c(0,1),
labels = c("Inactive", "Active"))
# 3. Drop SMILES for modeling
data_clean <- data %>% select(-SMILES)
table(data_clean$Label)
data <- read.csv("~/Desktop/drug_induced_ml/drug_induced_autoimmunity_prediction/DIA_trainingset_RDKit_descriptors.csv")
head(data$Label)
data$Label <- factor(data$Label,
levels = c(0, 1),
labels = c("Inactive", "Active"))
# Check again
table(data$Label)
data_clean <- data %>%
filter(!is.na(Label)) %>%
select(-SMILES)   # remove SMILES string column
# Check again
table(data_clean$Label)
library(caret)
library(recipes)
library(themis)    # for SMOTE
library(pROC)
library(dplyr)
set.seed(42)
# --- Train control ---
ctrl <- trainControl(
method = "cv",
number = 5,
sampling = "smote",          # balance classes in CV folds
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
)
rec_raw <- recipe(Label ~ ., data = data_clean) %>%
step_smote(Label)
fit_raw <- train(
rec_raw,
data = data_clean,
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
warnings()
data_fixed <- data_clean %>%
mutate(across(where(is.integer), as.numeric))
# Double-check types
str(data_fixed)
rec_raw <- recipe(Label ~ ., data = data_fixed %>% select(-SMILES)) %>%
step_smote(Label)
data_fixed <- data_clean %>%
mutate(across(where(is.integer), as.numeric))
# --- (1) RF on RAW DESCRIPTORS ---
rec_raw <- recipe(Label ~ ., data = data_fixed) %>%
step_smote(Label)
fit_raw <- train(
rec_raw,
data = data_fixed,
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
df_emb <- data.frame(Label = data_fixed$Label, emb)
rec_emb <- recipe(Label ~ ., data = df_emb) %>%
step_smote(Label)
fit_emb <- train(
rec_emb,
data = df_emb,
method = "rf",
metric = "ROC",
trControl = ctrl,
tuneLength = 3
)
roc_raw <- roc(fit_raw$pred$obs, fit_raw$pred$Active)
roc_emb <- roc(fit_emb$pred$obs, fit_emb$pred$Active)
plot(roc_raw, col = "blue", main = "ROC: Raw vs Embeddings")
plot(roc_emb, col = "red", add = TRUE)
legend("bottomright", legend = c("Raw Features", "Embeddings"),
col = c("blue", "red"), lwd = 2)
coords(roc_raw, "best", ret = c("threshold", "sensitivity", "specificity"))
coords(roc_emb, "best", ret = c("threshold", "sensitivity", "specificity"))
library(PRROC)
pr_raw <- pr.curve(
scores.class0 = fit_raw$pred$Active,
weights.class0 = as.numeric(fit_raw$pred$obs == "Active"),
curve = TRUE
)
# Embeddings
pr_emb <- pr.curve(
scores.class0 = fit_emb$pred$Active,
weights.class0 = as.numeric(fit_emb$pred$obs == "Active"),
curve = TRUE
)
cat("PR-AUC (Raw):", pr_raw$auc.integral, "\n")
cat("PR-AUC (Embeddings):", pr_emb$auc.integral, "\n")
# Plot curves
plot(pr_raw, col = "blue", main = "PR Curve: Raw vs Embeddings")
plot(pr_emb, col = "red", add = TRUE)
legend("topright", legend = c("Raw Features", "Embeddings"),
col = c("blue", "red"), lwd = 2)
stack_data <- data.frame(
Label = fit_raw$pred$obs,
Raw_RF = fit_raw$pred$Active,
Emb_RF = fit_emb$pred$Active
)
meta_fit <- train(
Label ~ .,
data = stack_data,
method = "xgb",
family = "binomial",
metric = "ROC",
trControl = trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
)
)
library(xgboost)
meta_fit <- train(
Label ~ .,
data = stack_data,
method = "xgbTree",
metric = "ROC",
trControl = trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
),
tuneLength = 5  # try a small hyperparameter grid
)
print(meta_fit)
stack_data <- data.frame(
Label   = fit_raw$pred$obs,
RF_raw  = fit_raw$pred$Active,
RF_emb  = fit_emb$pred$Active
)
# Convert labels to binary 0/1 for XGBoost
stack_data$Label <- ifelse(stack_data$Label == "Active", 1, 0)
dtrain <- xgb.DMatrix(
data = as.matrix(stack_data[, c("RF_raw", "RF_emb")]),
label = stack_data$Label
)
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
max_depth = 3,
eta = 0.1
)
xgb_meta <- xgb.train(
params = params,
data = dtrain,
nrounds = 200,
verbose = 0
)
meta_preds <- predict(xgb_meta, as.matrix(stack_data[, c("RF_raw", "RF_emb")]))
roc_meta <- roc(stack_data$Label, meta_preds)
plot(roc_meta, col = "purple", main = "Stacked Meta-Classifier ROC (XGBoost)")
auc(roc_meta)
plot(roc_meta, col = "purple", lwd = 2, main = "ROC Curves")
plot(roc_raw, col = "blue", add = TRUE)
plot(roc_emb, col = "red", add = TRUE)
legend("bottomright", legend = c("Raw", "Emb", "Stacked-XGB"),
col = c("blue", "red", "purple"), lwd = 2)
pr_meta <- pr.curve(
scores.class0 = meta_fit$pred$Active,
weights.class0 = as.numeric(meta_fit$pred$obs == "Active"),
curve = TRUE
)
cat("PR-AUC (Stacked XGB):", pr_meta$auc.integral, "\n")
library(mlr3verse)   # isotonic regression option
install.packages("mlr3verse")
library(mlr3verse)   # isotonic regression option
set.seed(123)
cal_idx <- createDataPartition(stack_data$Label, p = 0.7, list = FALSE)
train_cal <- stack_data[cal_idx, ]
test_cal  <- stack_data[-cal_idx, ]
probs <- predict(xgb_fit, newdata = test_cal, type = "prob")[, "Active"]
xgb_grid <- expand.grid(
nrounds = 200,
max_depth = 4,
eta = 0.1,
gamma = 0,
colsample_bytree = 0.8,
min_child_weight = 1,
subsample = 0.8
)
xgb_fit <- train(
Label ~ .,
data = train_cal,
method = "xgbTree",
metric = "ROC",
tuneGrid = xgb_grid,
trControl = trainControl(
method = "cv", number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
)
)
train_cal$Label <- factor(train_cal$Label, levels = c(0,1), labels = c("Inactive","Active"))
test_cal$Label  <- factor(test_cal$Label,  levels = c(0,1), labels = c("Inactive","Active"))
table(train_cal$Label)
table(test_cal$Label)
xgb_grid <- expand.grid(
nrounds = 200,
max_depth = 4,
eta = 0.1,
gamma = 0,
colsample_bytree = 0.8,
min_child_weight = 1,
subsample = 0.8
)
xgb_fit <- train(
Label ~ .,
data = train_cal,
method = "xgbTree",
metric = "ROC",
tuneGrid = xgb_grid,
trControl = trainControl(
method = "cv", number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
)
)
probs <- predict(xgb_fit, newdata = test_cal, type = "prob")[, "Active"]
platt_model <- glm(test_cal$Label ~ probs, family = binomial)
platt_probs <- predict(platt_model, type = "response")
roc_platt <- roc(test_cal$Label, platt_probs)
pr_platt  <- pr.curve(scores.class0 = platt_probs, weights.class0 = test_cal$Label == "Active")
print(roc_platt$auc)
print(pr_platt$auc.integral)
coords(roc_platt, "best", ret = c("threshold", "sensitivity", "specificity", "accuracy"))
xgb_train <- xgb.DMatrix(
data = as.matrix(stack_data[ , setdiff(names(stack_data), "Label")]),
label = as.numeric(stack_data$Label == "Active")
)
# Train a raw booster (same params as caret model)
bst <- xgb.train(
params = list(
objective = "binary:logistic",
eval_metric = "auc",
max_depth = 4,
eta = 0.1
),
data = xgb_train,
nrounds = 200
)
imp <- xgb.importance(model = bst)
xgb.plot.importance(imp, top_n = 20)
head(imp)
xgb_boost <- xgb_fit$finalModel
imp <- xgb.importance(model = xgb_boost)
xgb.plot.importance(imp, top_n = 20)
install.packages("SHAPforxgboost")
library(SHAPforxgboost)
shap_values <- shap.values(xgb_model = bst, X_train = as.matrix(stack_data[ , -1]))
# Summary plot
shap_long <- shap.prep(shap_contrib = shap_values$shap_score, X_train = stack_data[ , -1])
shap.plot.summary(shap_long)
shap.plot.dependence(shap_long, x = "emb_1", color_feature = "emb_2")
shap.plot.summary(shap_long)
head(shap_long)
shap.plot.dependence(shap_long, x = "emb_1", color_feature = "emb_2")
X <- as.matrix(data_clean %>% select(-Label))
y <- as.numeric(data_clean$Label) - 1
dtrain <- xgb.DMatrix(X, label = y)
xgb_direct <- xgboost(
data = dtrain,
objective = "binary:logistic",
nrounds = 200,
max_depth = 4,
eta = 0.1,
subsample = 0.8,
colsample_bytree = 0.8,
verbose = 0
)
shap_values <- shap.values(xgb_direct, X)
shap_long <- shap.prep(shap_contrib = shap_values$shap_score, X_train = X)
shap.plot.dependence(
shap_long,
x = "some_descriptor_or_embedding_column",
color_feature = "another_column"
)
combined_data <- cbind(
data_fixed %>% select(-Label),   # RDKit descriptors
emb_data %>% select(-Label),     # Mol2Vec embeddings
Label = data_fixed$Label         # response
)
setwd("~/")
args <- commandArgs(trailingOnly = TRUE)
if(length(args) < 2){
stop("Usage: Rscript extract_conservation_windows.R infile.csv outprefix [threshold] [minlen] [maxlen]")
}
library(tidyverse)
library(rcdk)
library(caret)
library(randomForest)
library(xgboost)
## ======================
df_raw <- read_delim("~/Downloads/3743.csv.csv", delim = ";")
df <- df_raw %>%
filter(`Standard Type` %in% c("IC50", "Ki")) %>%
filter(!is.na(Smiles), !is.na(`Standard Value`)) %>%
mutate(pIC50 = -log10(`Standard Value` * 1e-9)) %>%
# Clean SMILES strings in the original data to remove trailing tabs
mutate(Smiles = str_remove(Smiles, "\t$"))
## ====================================================================
## Step 2: Load ECFP4 fingerprints and align with activity data
## This uses the new fgfr4_ecfp4.csv file
## ====================================================================
fp_df <- read_csv("fgfr4_ecfp4.csv",
col_types = cols(.default = col_double(), smiles = col_character())) %>%
# Rename the smiles column to match the activity data for joining
rename(Smiles = smiles)
df_model <- inner_join(df, fp_df, by = "Smiles")
# Check to see how many rows are in the aligned data
cat("Rows in combined model data (df_model):", nrow(df_model), "\n")
## =============
## ====================================================================
## Step 3: Separate features (X) and target (y)
## Now X and y are guaranteed to be aligned
## ====================================================================
# Extract fingerprint columns, which start with "FP"
X <- df_model %>% select(starts_with("FP"))
x <- seq(0, 30, 0.1)
y <- dchisq(x, df = 7)
plot(x, y, type = "l", lwd = 2, col ="blue", main = "Chi-squared Distribution", xlab = "x", ylab = "Density")
plot(x, y, type = "l", lwd = 2, col ="red", main = "Chi-squared Distribution", xlab = "x", ylab = "Density")
abline(v = 7, col = "yellow", lty = 2)
legend("topright", legend = c("Chi-sq PDF", "Mean"), col = c("blue", "red"), lty = c(1,2), lwd = 3)
abline(v = 7, col = "green", lty = 2)
legend("topright", legend = c("Chi-sq PDF", "Mean"), col = c("blue", "red"), lty = c(1,2), lwd = 3)
f_values <- rf(10, df1 = 5, df2 = 2)
print(f_values)
qt(c(0.025, 0.975), df = 5)
x <- seq(-5, 5, length = 100)
y <- dt(x, df = 5)
plot(x, y, type = "l", lwd = 2, col ="orange", main = "Student t-Distribution", xlab = "x", ylab = "Density")
lines(x, dnorm(x), col = "red", lwd = 3, lty = 2)
legend("topright", legend = c("t", "Normal(0,1"), col = c("purple", "blue"), lwd = 3, lty = c(1,2))
setwd("~/Desktop/BioMoR")
devtools::build()
devtools::check()
devtools::build()
devtools::document()
devtools::build()
devtools::test()
devtools::test()
devtools::check()
devtools::document()
devtools::document()
devtools::test()
devtools::check()
devtools::document()
devtools::test()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::install()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
